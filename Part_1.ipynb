{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 Basic OpenCV Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image To Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('images/grayscale.jpg')\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "else:\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Show the grayscale image\n",
    "    cv2.imshow('Grayscale Image', grayscale_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"images/fabric.png\")\n",
    "\n",
    "# Show the original image\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 150, 200)\n",
    "\n",
    "# Show the Canny edge-detected image\n",
    "cv2.imshow(\"Canny Image\", canny_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrating Morphological Erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image (ensure the image is binary, i.e., black and white)\n",
    "image = cv2.imread('images/erosion.jpg', 0)  # Read in grayscale mode\n",
    "\n",
    "# Threshold the image to create a binary image (if it isn't already binary)\n",
    "_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Create a kernel (a 3x3 matrix of ones)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "# Apply morphological erosion\n",
    "eroded_image = cv2.erode(binary_image, kernel, iterations=1)\n",
    "\n",
    "# Display the original and eroded image\n",
    "cv2.imshow('Original Image', binary_image)\n",
    "cv2.imshow('Eroded Image', eroded_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrating Morphilogical Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"images/dilation.jpeg\")\n",
    "\n",
    "# Display the original image\n",
    "cv2.imshow(\"Original\", image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "canny_image = cv2.Canny(gray, 150, 200)\n",
    "cv2.imshow(\"Canny Image\", canny_image)\n",
    "\n",
    "#Dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilate_image = cv2.dilate(canny_image, kernel, iterations=1)\n",
    "cv2.imshow(\"Dilated\", dilate_image)\n",
    "\n",
    "# Wait for a key press and close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Noise In Photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "image5 = cv2.imread('images/noise.png')\n",
    "\n",
    "# Check if the image was loaded correctly\n",
    "if image5 is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "    exit()\n",
    "\n",
    "# Gaussian Blur\n",
    "gaussian_blur = cv2.GaussianBlur(image5, (5, 5), 0)\n",
    "\n",
    "# Median Blur\n",
    "median_blur = cv2.medianBlur(image5, 5)\n",
    "\n",
    "# Bilateral Filter\n",
    "bilateral_filter = cv2.bilateralFilter(image5, 9, 75, 75)\n",
    "\n",
    "# Comparing Images\n",
    "cv2.imshow('Original Image', image5)\n",
    "cv2.imshow('Gaussian Blur', gaussian_blur)\n",
    "cv2.imshow('Median Blur', median_blur)\n",
    "cv2.imshow('Bilateral Filter', bilateral_filter)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing Geometric Shapes on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image6 = cv2.imread('images/blank-canvas.jpg')\n",
    "\n",
    "# Drawing Functions\n",
    "# Draw a Circle\n",
    "cv2.circle(image6, (375, 300), 100, (198, 207, 243), 15)\n",
    "# Draw a Rectangle\n",
    "cv2.rectangle(image6, (250, 100), (500, 500), (107, 50, 50), 15)\n",
    "# Draw a Line\n",
    "cv2.line(image6, (200, 2000), (200, 60), (255, 0, 0), 3)\n",
    "# Write Text\n",
    "cv2.putText(image6, \"Machine Vision\", (160, 120), cv2.FONT_HERSHEY_SCRIPT_COMPLEX, 2, (0, 0, 255), 2)\n",
    "\n",
    "# Display the Image\n",
    "cv2.imshow('Shapes', image6)\n",
    "\n",
    "# Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Text To Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/add text.jpg')\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Unable to load image.\")\n",
    "    exit()\n",
    "\n",
    "# text to be added\n",
    "text = \"Iris Versicolor\"\n",
    "\n",
    "# posiition of text\n",
    "position = (150, 450)\n",
    "\n",
    "# font Type\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "# font size\n",
    "font_scale = 2\n",
    "\n",
    "# text color (BGR format)\n",
    "color = (255, 255, 255)  # white\n",
    "\n",
    "# thickness of text\n",
    "thickness = 2\n",
    "\n",
    "# add the text to the image with the previous specification\n",
    "cv2.putText(image, text, position, font, font_scale, color, thickness)\n",
    "\n",
    "# display text\n",
    "cv2.imshow('Image with Text', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolating Objects By Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"images/pattern.jpg\")\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the HSV range for the color \n",
    "lower_blue = np.array([90, 50, 50])  # Lower bound of blue in HSV\n",
    "upper_blue = np.array([130, 255, 255])  # Upper bound of blue in HSV\n",
    "\n",
    "\n",
    "# Create a mask for the blue color\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "result1 = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "# Display the original image, mask, and result\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Blue Mask\", mask)\n",
    "cv2.imshow(\"Extracted Blue Objects\", result1)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlining Shapes With Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found a circle\n",
      "We have a hexagon here\n",
      "We found a circle\n",
      "We found a circle\n",
      "We found a square\n",
      "We found a square\n",
      "We found a triangle\n",
      "We found a triangle\n",
      "We found a circle\n",
      "We found a circle\n",
      "We found a square\n",
      "We found a circle\n",
      "We found a circle\n",
      "We found a square\n",
      "We found a square\n",
      "We have a hexagon here\n",
      "We found a circle\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"images/shapes.png\")\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(gray,50,255,1)\n",
    "contours,h = cv2.findContours(thresh,1,2)\n",
    "# cv2_imshow(thresh)\n",
    "for cnt in contours:\n",
    "  approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "  n = len(approx)\n",
    "  if n==6:\n",
    "    # this is a hexagon\n",
    "    print(\"We have a hexagon here\")\n",
    "    cv2.drawContours(img,[cnt],0,255,10)\n",
    "  elif n==3:\n",
    "    # this is a triangle\n",
    "    print(\"We found a triangle\")\n",
    "    cv2.drawContours(img,[cnt],0,(0,255,0),3)\n",
    "  elif n>9:\n",
    "    # this is a circle\n",
    "    print(\"We found a circle\")\n",
    "    cv2.drawContours(img,[cnt],0,(0,255,255),3)\n",
    "  elif n==4:\n",
    "    # this is a Square\n",
    "    print(\"We found a square\")\n",
    "    cv2.drawContours(img,[cnt],0,(255,255,0),3)\n",
    "cv2.imshow(\"shapes\",img)\n",
    "cv2.waitKey(0)  # Wait for any key press\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking a Ball in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('videos/ball track.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # frame read\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # if vid end, break\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    \n",
    "    # use Hough Circle Transform to detect circles\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, 1.2, minDist=100,\n",
    "                               param1=100, param2=30, minRadius=70, maxRadius=95)\n",
    "    \n",
    "    # process if circles found\n",
    "    if circles is not None:\n",
    "        # circle coordinate to integer\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        \n",
    "        for (x, y, r) in circles:\n",
    "            # draw the circle perimiter in green\n",
    "            cv2.circle(frame, (x, y), r, (0, 255, 0), 4)\n",
    "            # draw the circle center in red\n",
    "            cv2.circle(frame, (x, y), 5, (0, 0, 255), 4)\n",
    "    \n",
    "    # display video\n",
    "    cv2.imshow('Ball Tracking using Hough Circles', frame)\n",
    "    \n",
    "    # close vide if \"q\" is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Contours For Shape Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/contour.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# thresholding to create a binary image\n",
    "_, thresh = cv2.threshold(gray, 185, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# find contours in the thresholded image\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# create a copy of the image to draw contours on\n",
    "contour_image = image.copy()\n",
    "\n",
    "# loop through each contour and perform shape analysis\n",
    "for contour in contours:\n",
    "    # area of the contour\n",
    "    area = cv2.contourArea(contour)\n",
    "    \n",
    "    # perimeter of the contour\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # draw the contour on the image\n",
    "    cv2.drawContours(contour_image, [contour], -1, (0, 255, 0), 2)  # Green contour\n",
    "\n",
    "cv2.imshow(\"Contours\", contour_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Image to Blurring Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"images/portrait.jpg\")\n",
    "\n",
    "\n",
    "#Gaussian Blur\n",
    "gaussian_blur = cv2.GaussianBlur(image, (15, 15), 0)\n",
    "\n",
    " #Median Blur\n",
    "median_blur = cv2.medianBlur(image, 15)\n",
    "\n",
    "# Average (Box) Blur\n",
    "average_blur = cv2.blur(image, (15, 15))\n",
    "\n",
    "# Display the original image and blurred images\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Gaussian Blur\", gaussian_blur)\n",
    "cv2.imshow(\"Median Blur\", median_blur)\n",
    "cv2.imshow(\"Average Blur\", average_blur)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenting Image Based On Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/segmen.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# thresholding on edge detection \n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# find contours\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# create a blank mask to draw the contours\n",
    "mask = np.zeros_like(image)\n",
    "\n",
    "# draw contours on the mask (or on the original image)\n",
    "cv2.drawContours(mask, contours, -1, (0, 255, 0), 2)  # Green color for contours\n",
    "\n",
    "# create a mask to extract the segmented parts\n",
    "segmented_image = cv2.drawContours(np.zeros_like(image), contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "# comparison of the original image, the thresholded image, and the result with contours\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Thresholded Image', thresh)\n",
    "cv2.imshow('Contours on Mask', mask)\n",
    "cv2.imshow('Segmented Image', segmented_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Erosion And Dilation for Feature Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('images/bbm.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the kernel (a 3x3 square kernel)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "#rosion\n",
    "eroded_image = cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "#dilation on the eroded image\n",
    "dilated_image = cv2.dilate(eroded_image, kernel, iterations=1)\n",
    "\n",
    "\n",
    "cv2.imshow('Refined Image', dilated_image)\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
